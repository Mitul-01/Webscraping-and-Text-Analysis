{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb36493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  #data maniplulation\n",
    "import requests  #for sending HTTP requests\n",
    "from bs4 import BeautifulSoup #for web scraping\n",
    "import nltk #for natural language processing\n",
    "import re #for string manipulation.\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer  #for sentiment analysis\n",
    "from nltk.tokenize import word_tokenize  #for tokenize\n",
    "from nltk.corpus import stopwords     #for all stopwords         \n",
    "from nltk.tokenize import RegexpTokenizer #tokenize a string or text based on a regular expression \n",
    "from nltk.stem import WordNetLemmatizer   #for lemmatize a word\n",
    "from textblob import TextBlob #for processing textual data\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83d1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdetails(url):\n",
    "    page = requests.get(url, headers={\"User-Agent\": \"XY\"})\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    article_text = soup.find('div', class_='td-post-content').get_text()\n",
    "    #create a tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    #tokenize the text\n",
    "    tokens = tokenizer.tokenize(article_text)\n",
    "    #read in txt file containing stopwords\n",
    "    stopwords_file = open(\"All_stopwords.txt\", \"r\") #All_stopwords is a text file which made by me which have all the 5 stopwords provided from company\n",
    "    #create a set of stopwords\n",
    "    All_stopwords = set()\n",
    "    #loop through the text file\n",
    "    for line in stopwords_file:\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        All_stopwords.add(line)\n",
    "    #remove stopwords\n",
    "    filtered_tokens = [w for w in tokens if not w in All_stopwords]\n",
    "    #create a lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #lemmatize the tokens\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(w) for w in filtered_tokens] \n",
    "    #calculate word count\n",
    "    word_count = len(lemmatized_tokens)\n",
    "    #calculate avg word length\n",
    "    avg_word_length = 0\n",
    "    for i in lemmatized_tokens:\n",
    "        avg_word_length += len(i)\n",
    "    avg_word_length = avg_word_length/word_count\n",
    "    #calculate syllable count per word\n",
    "    syllable_count_per_word = 0\n",
    "    for i in lemmatized_tokens:\n",
    "        syllable_count_per_word += len(i.split('-'))\n",
    "    syllable_count_per_word = syllable_count_per_word/word_count\n",
    "    #calculate personal pronouns\n",
    "    personal_pronouns = 0\n",
    "    for w in lemmatized_tokens:\n",
    "        if w in [\"I\", \"me\", \"you\", \"he\", \"him\", \"she\", \"her\", \"it\", \"we\", \"us\", \"they\", \"them\"]:\n",
    "            personal_pronouns += 1\n",
    "    #create a function to calculate the positive and negative scores\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    polarity_score = sid.polarity_scores(article_text)\n",
    "    #calculate positive and negative score\n",
    "    positive_score = polarity_score['pos']\n",
    "    negative_score = polarity_score['neg']\n",
    "    #sentiment analysis such as polarity and subjectivity\n",
    "    text = TextBlob(article_text)\n",
    "    polarity = text.sentiment.polarity\n",
    "    subjective = text.sentiment.subjectivity\n",
    "    #calculate complex word count\n",
    "    complex_words = 0\n",
    "    for w in lemmatized_tokens:\n",
    "        syllable_count = len(w.split('-'))\n",
    "        if syllable_count > 2:\n",
    "            complex_words += 1\n",
    "    #calculate average sentence length\n",
    "    sentences = article_text.split('.')\n",
    "    avg_sentence_length = 0\n",
    "    for s in sentences:\n",
    "        avg_sentence_length += len(s.split())\n",
    "    avg_sentence_length = avg_sentence_length/len(sentences)\n",
    "    #calculate the Gunning Fog Index\n",
    "    fog_index = 0.4 * (avg_sentence_length +(100 * complex_words/word_count))\n",
    "    #complex word percentage\n",
    "    complex_words_percentage = (complex_words/word_count)*100\n",
    "    #calculate the average number of words per sentence\n",
    "    avg_words_per_sentence = word_count/len(sentences)\n",
    "    \n",
    "    return[positive_score,negative_score,polarity,subjective,avg_sentence_length,complex_words_percentage,fog_index,avg_words_per_sentence,complex_words,\n",
    "            word_count, syllable_count_per_word, personal_pronouns, avg_word_length]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ad4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_excel(\"Output Data Structure.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40b71fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               NaN             NaN             NaN                 NaN   \n",
       "1               NaN             NaN             NaN                 NaN   \n",
       "2               NaN             NaN             NaN                 NaN   \n",
       "3               NaN             NaN             NaN                 NaN   \n",
       "4               NaN             NaN             NaN                 NaN   \n",
       "..              ...             ...             ...                 ...   \n",
       "109             NaN             NaN             NaN                 NaN   \n",
       "110             NaN             NaN             NaN                 NaN   \n",
       "111             NaN             NaN             NaN                 NaN   \n",
       "112             NaN             NaN             NaN                 NaN   \n",
       "113             NaN             NaN             NaN                 NaN   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                    NaN                          NaN        NaN   \n",
       "1                    NaN                          NaN        NaN   \n",
       "2                    NaN                          NaN        NaN   \n",
       "3                    NaN                          NaN        NaN   \n",
       "4                    NaN                          NaN        NaN   \n",
       "..                   ...                          ...        ...   \n",
       "109                  NaN                          NaN        NaN   \n",
       "110                  NaN                          NaN        NaN   \n",
       "111                  NaN                          NaN        NaN   \n",
       "112                  NaN                          NaN        NaN   \n",
       "113                  NaN                          NaN        NaN   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                 NaN                 NaN         NaN   \n",
       "1                                 NaN                 NaN         NaN   \n",
       "2                                 NaN                 NaN         NaN   \n",
       "3                                 NaN                 NaN         NaN   \n",
       "4                                 NaN                 NaN         NaN   \n",
       "..                                ...                 ...         ...   \n",
       "109                               NaN                 NaN         NaN   \n",
       "110                               NaN                 NaN         NaN   \n",
       "111                               NaN                 NaN         NaN   \n",
       "112                               NaN                 NaN         NaN   \n",
       "113                               NaN                 NaN         NaN   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                  NaN                NaN              NaN  \n",
       "1                  NaN                NaN              NaN  \n",
       "2                  NaN                NaN              NaN  \n",
       "3                  NaN                NaN              NaN  \n",
       "4                  NaN                NaN              NaN  \n",
       "..                 ...                ...              ...  \n",
       "109                NaN                NaN              NaN  \n",
       "110                NaN                NaN              NaN  \n",
       "111                NaN                NaN              NaN  \n",
       "112                NaN                NaN              NaN  \n",
       "113                NaN                NaN              NaN  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "411f9188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n"
     ]
    }
   ],
   "source": [
    "for i in output.index:\n",
    "    try:\n",
    "        result = getdetails(output[\"URL\"][i])\n",
    "        if len(result)==13:\n",
    "            for jdx,j in enumerate(output.columns[2:]):\n",
    "                output[j][i]=result[jdx]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218d1f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.136936</td>\n",
       "      <td>0.463364</td>\n",
       "      <td>22.974359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.189744</td>\n",
       "      <td>13.743590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.060634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.074693</td>\n",
       "      <td>0.433596</td>\n",
       "      <td>19.901408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.960563</td>\n",
       "      <td>9.225352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.422901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.111470</td>\n",
       "      <td>0.483201</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.142050</td>\n",
       "      <td>0.487387</td>\n",
       "      <td>19.891566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.956627</td>\n",
       "      <td>9.156627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.448684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.053178</td>\n",
       "      <td>0.509139</td>\n",
       "      <td>21.317073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.526829</td>\n",
       "      <td>11.231707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.490771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.035488</td>\n",
       "      <td>0.402814</td>\n",
       "      <td>16.962963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.785185</td>\n",
       "      <td>9.907407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.553271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.076504</td>\n",
       "      <td>0.391713</td>\n",
       "      <td>18.987952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.595181</td>\n",
       "      <td>11.506024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.102618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.040319</td>\n",
       "      <td>0.417892</td>\n",
       "      <td>15.917808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.367123</td>\n",
       "      <td>9.109589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.493233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.208748</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>23.161290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.264516</td>\n",
       "      <td>12.967742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.457711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.124963</td>\n",
       "      <td>0.459020</td>\n",
       "      <td>16.092308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.436923</td>\n",
       "      <td>8.646154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.585409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0             0.145           0.044        0.136936            0.463364   \n",
       "1             0.149           0.084        0.074693            0.433596   \n",
       "2             0.075           0.036        0.111470            0.483201   \n",
       "3             0.145           0.044        0.142050            0.487387   \n",
       "4             0.147           0.050        0.053178            0.509139   \n",
       "..              ...             ...             ...                 ...   \n",
       "109           0.129           0.051        0.035488            0.402814   \n",
       "110           0.110           0.020        0.076504            0.391713   \n",
       "111           0.091           0.092        0.040319            0.417892   \n",
       "112           0.170           0.004        0.208748            0.546448   \n",
       "113           0.186           0.082        0.124963            0.459020   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0              22.974359                          0.0   9.189744   \n",
       "1              19.901408                          0.0   7.960563   \n",
       "2              20.000000                          0.0   8.000000   \n",
       "3              19.891566                          0.0   7.956627   \n",
       "4              21.317073                          0.0   8.526829   \n",
       "..                   ...                          ...        ...   \n",
       "109            16.962963                          0.0   6.785185   \n",
       "110            18.987952                          0.0   7.595181   \n",
       "111            15.917808                          0.0   6.367123   \n",
       "112            23.161290                          0.0   9.264516   \n",
       "113            16.092308                          0.0   6.436923   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                           13.743590                 0.0      1072.0   \n",
       "1                            9.225352                 0.0       655.0   \n",
       "2                           10.941176                 0.0       930.0   \n",
       "3                            9.156627                 0.0       760.0   \n",
       "4                           11.231707                 0.0       921.0   \n",
       "..                                ...                 ...         ...   \n",
       "109                          9.907407                 0.0       535.0   \n",
       "110                         11.506024                 0.0       955.0   \n",
       "111                          9.109589                 0.0       665.0   \n",
       "112                         12.967742                 0.0       402.0   \n",
       "113                          8.646154                 0.0       562.0   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                  1.0                0.0         7.060634  \n",
       "1                  1.0                0.0         6.422901  \n",
       "2                  1.0                0.0         7.096774  \n",
       "3                  1.0                0.0         6.448684  \n",
       "4                  1.0                0.0         6.490771  \n",
       "..                 ...                ...              ...  \n",
       "109                1.0                6.0         6.553271  \n",
       "110                1.0                0.0         6.102618  \n",
       "111                1.0                0.0         6.493233  \n",
       "112                1.0                0.0         7.457711  \n",
       "113                1.0                1.0         6.585409  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c02c72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_excel('final Output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a93a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
